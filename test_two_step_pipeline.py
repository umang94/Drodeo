#!/usr/bin/env python3
"""
Two-Step Gemini Pipeline Test Script

Tests the complete two-step pipeline:
1. Step 1: Multimodal Analysis (GeminiMultimodalAnalyzer)
2. Step 2: Self-Translation (GeminiSelfTranslator)  
3. Step 3: Video Creation (VideoEditor.create_from_instructions)

IMPORTANT: Uses input_dev/ videos for fast development testing (35-70x faster)
"""

import os
import sys
import time
import json
from pathlib import Path
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Add src to path for imports
sys.path.append('src')

from src.core.gemini_multimodal_analyzer import GeminiMultimodalAnalyzer
from src.core.gemini_self_translator import GeminiSelfTranslator
from src.editing.video_editor import VideoEditor

def test_two_step_pipeline():
    """Test the complete two-step Gemini pipeline"""
    
    print("üß™ TESTING TWO-STEP GEMINI PIPELINE")
    print("=" * 60)
    
    # Test configuration - ALWAYS use input_dev/ for development
    music_path = "music_input/Fractite - Quicky-qPBvJ6E7RXY.mp3"
    video_paths = [
        "input_dev/DJI_0108_dev.MP4",
        "input_dev/DJI_0110_dev.MP4", 
        "input_dev/DJI_0121_dev.MP4",
        "input_dev/IMG_7840_dev.mov",
        "input_dev/IMG_7841_dev.mov",
        "input_dev/IMG_7842_dev.mov"
    ]
    
    # Verify test files exist
    print("üìÇ Verifying test files...")
    if not os.path.exists(music_path):
        print(f"‚ùå Music file not found: {music_path}")
        return False
    
    available_videos = []
    for video_path in video_paths:
        if os.path.exists(video_path):
            available_videos.append(video_path)
            print(f"   ‚úÖ {os.path.basename(video_path)} ({os.path.getsize(video_path) / (1024*1024):.1f} MB)")
        else:
            print(f"   ‚ö†Ô∏è  Missing: {video_path}")
    
    if len(available_videos) < 2:
        print(f"‚ùå Need at least 2 videos for testing, found {len(available_videos)}")
        return False
    
    print(f"‚úÖ Test files ready: 1 audio + {len(available_videos)} low-res development videos")
    
    try:
        # Step 1: Multimodal Analysis
        print("\nüìä Step 1: Initialize Gemini Multimodal Analyzer")
        analyzer = GeminiMultimodalAnalyzer()
        
        print("üìä Step 2: Perform Multimodal Analysis")
        start_time = time.time()
        
        multimodal_result = analyzer.analyze_batch(
            audio_path=music_path,
            video_paths=available_videos
        )
        
        step1_time = time.time() - start_time
        print(f"   ‚úÖ Step 1 completed in {step1_time:.1f}s")
        print(f"   üìä Audio duration: {multimodal_result.audio_duration:.1f}s")
        print(f"   üìä Audio BPM: {multimodal_result.audio_tempo}")
        print(f"   üìä Sync confidence: {multimodal_result.sync_confidence:.2f}")
        print(f"   üìä Reasoning length: {len(multimodal_result.gemini_reasoning)} characters")
        
        # Step 2: Self-Translation
        print("\nü§ñ Step 3: Initialize Gemini Self-Translator")
        translator = GeminiSelfTranslator()
        
        print("ü§ñ Step 4: Perform Self-Translation")
        start_time = time.time()
        
        # Get video durations for validation
        video_durations = {}
        for video_path in available_videos:
            try:
                from moviepy.editor import VideoFileClip
                temp_clip = VideoFileClip(video_path)
                video_durations[os.path.basename(video_path)] = temp_clip.duration
                temp_clip.close()
            except Exception as e:
                logger.warning(f"Failed to get duration for {video_path}: {e}")
                video_durations[os.path.basename(video_path)] = 60.0  # Fallback duration
        
        available_video_names = [os.path.basename(path) for path in available_videos]
        editing_instructions = translator.translate_timeline(
            gemini_reasoning=multimodal_result.gemini_reasoning,
            audio_duration=multimodal_result.audio_duration,
            available_videos=available_video_names,
            video_durations=video_durations  # Pass actual durations
        )
        
        step2_time = time.time() - start_time
        print(f"   ‚úÖ Step 2 completed in {step2_time:.1f}s")
        print(f"   üìä Clips generated: {len(editing_instructions.clips)}")
        print(f"   üìä Transitions: {len(editing_instructions.transitions)}")
        print(f"   üìä Translation confidence: {editing_instructions.metadata.get('confidence', 'N/A')}")
        
        # Validate instructions
        print("\nüîç Step 5: Validate Editing Instructions")
        is_valid = translator.validate_instructions(editing_instructions, available_video_names)
        if not is_valid:
            print("‚ùå Editing instructions validation failed")
            return False
        print("   ‚úÖ Editing instructions validation passed")
        
        # Step 3: Video Creation
        print("\nüé¨ Step 6: Initialize Video Editor")
        editor = VideoEditor()
        
        print("üé¨ Step 7: Create Video from Instructions")
        start_time = time.time()
        
        # Update video paths in instructions to full paths
        for clip_data in editing_instructions.clips:
            video_name = clip_data['video_path']
            # Find full path for this video name
            for full_path in available_videos:
                if os.path.basename(full_path) == video_name:
                    clip_data['video_path'] = full_path
                    break
        
        output_path = editor.create_from_instructions(
            instructions=editing_instructions,
            music_name="TwoStep_Pipeline_Test",
            music_path=music_path
        )
        
        step3_time = time.time() - start_time
        print(f"   ‚úÖ Step 3 completed in {step3_time:.1f}s")
        
        # Verify output
        print("\n‚úÖ Step 8: Verify Output")
        if os.path.exists(output_path):
            file_size = os.path.getsize(output_path) / (1024 * 1024)  # MB
            print(f"   üìÅ Output: {os.path.basename(output_path)}")
            print(f"   üíæ File size: {file_size:.1f} MB")
            
            # Get video info
            video_info = editor.get_video_info(output_path)
            if video_info:
                print(f"   üéµ Video duration: {video_info.get('duration', 'N/A'):.1f}s")
                print(f"   üì∫ Resolution: {video_info.get('width', 'N/A')}x{video_info.get('height', 'N/A')}")
                print(f"   üéµ Has audio: {video_info.get('has_audio', 'N/A')}")
            
            print("   ‚úÖ Output verification successful")
        else:
            print(f"   ‚ùå Output file not found: {output_path}")
            return False
        
        # Summary
        total_time = step1_time + step2_time + step3_time
        print(f"\nüéâ TWO-STEP PIPELINE TEST RESULTS:")
        print(f"   üìä Step 1 (Multimodal Analysis): {step1_time:.1f}s")
        print(f"   ü§ñ Step 2 (Self-Translation): {step2_time:.1f}s")
        print(f"   üé¨ Step 3 (Video Creation): {step3_time:.1f}s")
        print(f"   ‚è±Ô∏è  Total time: {total_time:.1f}s")
        print(f"   üí∞ Estimated cost: ~$0.26 (${0.25:.2f} + ${0.01:.2f})")
        print(f"   ‚úÖ SUCCESS: Two-step pipeline working perfectly!")
        
        # Save test results
        test_results = {
            "timestamp": time.time(),
            "test_type": "two_step_pipeline",
            "music_file": os.path.basename(music_path),
            "video_files": [os.path.basename(p) for p in available_videos],
            "step1_time": step1_time,
            "step2_time": step2_time,
            "step3_time": step3_time,
            "total_time": total_time,
            "audio_duration": multimodal_result.audio_duration,
            "audio_bpm": multimodal_result.audio_tempo,
            "sync_confidence": multimodal_result.sync_confidence,
            "clips_generated": len(editing_instructions.clips),
            "transitions_generated": len(editing_instructions.transitions),
            "translation_confidence": editing_instructions.metadata.get('confidence', 0),
            "output_file": os.path.basename(output_path),
            "output_size_mb": file_size,
            "success": True
        }
        
        results_file = f"two_step_pipeline_results_{int(time.time())}.json"
        with open(results_file, 'w') as f:
            json.dump(test_results, f, indent=2)
        
        print(f"   üìÑ Test results saved: {results_file}")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå TWO-STEP PIPELINE TEST FAILED: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def test_individual_components():
    """Test individual components separately"""
    
    print("\nüîß TESTING INDIVIDUAL COMPONENTS")
    print("=" * 60)
    
    try:
        # Test GeminiSelfTranslator with sample data
        print("ü§ñ Testing GeminiSelfTranslator with sample data...")
        
        translator = GeminiSelfTranslator()
        
        sample_reasoning = """
        AUDIO ANALYSIS:
        Duration: 79.1 seconds
        BPM: 92.3
        Structure: Electronic intro (0:00-0:10), Build-up (0:10-0:30), Drop (0:30-0:50), Outro (0:50-1:19)
        
        VIDEO CONTENT DISCOVERED:
        Video 1 (DJI_0108_dev.MP4): Aerial Seattle cityscape, calm energy, best segments 0:00-0:20
        Video 2 (IMG_7840_dev.mov): Ground-level bridge walkway, medium energy, best segment 0:05-0:15
        
        CREATIVE TIMELINE:
        0:00-0:10 (Intro): Use Video 1 aerial cityscape (0:00-0:10) for establishing mood
        0:10-0:30 (Build-up): Transition to Video 2 bridge walkway (0:05-0:25) as energy increases
        0:30-0:50 (Drop): Switch back to Video 1 aerial (0:20-0:40) for climax
        0:50-1:19 (Outro): Use Video 2 bridge (0:10-0:39) for calm ending
        """
        
        available_videos = ["DJI_0108_dev.MP4", "IMG_7840_dev.mov"]
        
        instructions = translator.translate_timeline(
            gemini_reasoning=sample_reasoning,
            audio_duration=79.1,
            available_videos=available_videos
        )
        
        print(f"   ‚úÖ Self-translation successful!")
        print(f"   üìä Clips: {len(instructions.clips)}")
        print(f"   üìä Transitions: {len(instructions.transitions)}")
        print(f"   üìä Confidence: {instructions.metadata.get('confidence', 'N/A')}")
        
        # Validate instructions
        is_valid = translator.validate_instructions(instructions, available_videos)
        print(f"   üìä Validation: {'‚úÖ Passed' if is_valid else '‚ùå Failed'}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Component test failed: {str(e)}")
        return False

def main():
    """Main test function"""
    print("üöÄ TWO-STEP GEMINI PIPELINE TESTING SUITE")
    print("=" * 60)
    print("üìã Development Guidelines:")
    print("   - Using input_dev/ videos for 35-70x faster processing")
    print("   - Low-resolution videos reduce API costs and processing time")
    print("   - Perfect for development and testing iterations")
    print()
    
    # Test individual components first
    component_success = test_individual_components()
    
    if component_success:
        # Test complete pipeline
        pipeline_success = test_two_step_pipeline()
        
        if pipeline_success:
            print("\nüéâ ALL TESTS PASSED!")
            print("   ‚úÖ Individual components working")
            print("   ‚úÖ Complete two-step pipeline working")
            print("   ‚úÖ Ready for production implementation")
        else:
            print("\n‚ö†Ô∏è  PIPELINE TEST FAILED")
            print("   ‚úÖ Individual components working")
            print("   ‚ùå Complete pipeline needs debugging")
    else:
        print("\n‚ùå COMPONENT TESTS FAILED")
        print("   ‚ùå Individual components need fixing")
        print("   ‚è∏Ô∏è  Pipeline test skipped")

if __name__ == "__main__":
    main()
